{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#khai báo thư viện\nfrom keras import datasets, Sequential\nfrom keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nfrom keras.utils import np_utils\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.preprocessing import  image\nfrom keras.preprocessing.image import load_img, img_to_array,array_to_img,ImageDataGenerator\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nimport os\nimport cv2 \nimport glob","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-20T08:33:10.237773Z","iopub.execute_input":"2022-05-20T08:33:10.238089Z","iopub.status.idle":"2022-05-20T08:33:10.246770Z","shell.execute_reply.started":"2022-05-20T08:33:10.238060Z","shell.execute_reply":"2022-05-20T08:33:10.245891Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_img():\n    image=[]\n    names=['1000','10000','100000','200','2000','20000',\n         '200000','500','5000','50000','500000']\n    for name in names:\n        path=glob.glob(f'../input/money123/{name}/*')\n        for i, pic in enumerate(path):\n            img = cv2.imread(path[i])/255\n            img=cv2.resize(img,(224,224))\n            image.append(img)\n    image=np.array(image)\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:32:43.342988Z","iopub.execute_input":"2022-05-20T08:32:43.343816Z","iopub.status.idle":"2022-05-20T08:32:43.350084Z","shell.execute_reply.started":"2022-05-20T08:32:43.343754Z","shell.execute_reply":"2022-05-20T08:32:43.349373Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"image=get_img()\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:33:47.947249Z","iopub.execute_input":"2022-05-20T08:33:47.947542Z","iopub.status.idle":"2022-05-20T08:33:51.579816Z","shell.execute_reply.started":"2022-05-20T08:33:47.947504Z","shell.execute_reply":"2022-05-20T08:33:51.578896Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"labels=[]\nmon_1000=glob.glob('../input/money123/1000/*')\nmon_10000=glob.glob('../input/money123/10000/*')\nmon_100000=glob.glob('../input/money123/100000/*')\nmon_200=glob.glob('../input/money123/200/*')\nmon_2000=glob.glob('../input/money123/2000/*')\nmon_20000=glob.glob('../input/money123/20000/*')\nmon_200000=glob.glob('../input/money123/200000/*')\nmon_500=glob.glob('../input/money123/500/*')\nmon_5000=glob.glob('../input/money123/5000/*')\nmon_50000=glob.glob('../input/money123/50000/*')\nmon_500000=glob.glob('../input/money123/500000/*')\nfor i in mon_1000:\n    labels.append(0) \nfor i in mon_10000:\n    labels.append(1) \nfor i in mon_100000:\n    labels.append(2)  \nfor i in mon_200 :\n    labels.append(3)\nfor i in mon_2000:\n    labels.append(4)\nfor i in mon_20000:\n    labels.append(5)\nfor i in mon_200000:\n    labels.append(6)\nfor i in mon_500:\n    labels.append(7)   \nfor i in mon_5000:\n    labels.append(8)\nfor i in mon_50000:\n    labels.append(9)\nfor i in mon_500000:\n    labels.append(10)\nlabels=np.array(labels)\nlabels=labels.reshape(labels.shape[0],1)\nlabels=to_categorical(labels,11)\nlabels.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:33:14.296542Z","iopub.execute_input":"2022-05-20T08:33:14.296809Z","iopub.status.idle":"2022-05-20T08:33:14.318955Z","shell.execute_reply.started":"2022-05-20T08:33:14.296780Z","shell.execute_reply":"2022-05-20T08:33:14.317854Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"labels.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:33:24.964188Z","iopub.execute_input":"2022-05-20T08:33:24.964529Z","iopub.status.idle":"2022-05-20T08:33:24.970048Z","shell.execute_reply.started":"2022-05-20T08:33:24.964488Z","shell.execute_reply":"2022-05-20T08:33:24.969367Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten # BatchNormalization: để dùng GPU ko lỗi\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:54:04.642144Z","iopub.execute_input":"2022-05-20T08:54:04.642776Z","iopub.status.idle":"2022-05-20T08:54:04.649358Z","shell.execute_reply.started":"2022-05-20T08:54:04.642722Z","shell.execute_reply":"2022-05-20T08:54:04.648768Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:54:08.916731Z","iopub.execute_input":"2022-05-20T08:54:08.917038Z","iopub.status.idle":"2022-05-20T08:54:08.922039Z","shell.execute_reply.started":"2022-05-20T08:54:08.917003Z","shell.execute_reply":"2022-05-20T08:54:08.920826Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten # BatchNormalization: để dùng GPU ko lỗi\nfrom tensorflow.keras.optimizers import SGD\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224,224,3)))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(11, activation='softmax'))\n\n\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(image,labels,callbacks = [early_stopping],batch_size=8,epochs=20, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:54:49.649798Z","iopub.execute_input":"2022-05-20T08:54:49.650100Z","iopub.status.idle":"2022-05-20T08:57:50.793009Z","shell.execute_reply.started":"2022-05-20T08:54:49.650067Z","shell.execute_reply":"2022-05-20T08:57:50.792155Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import load_img, img_to_array\nimport numpy as np\nfilename = \"../input/money123/2000/15.jpg\"\n\nimg = load_img(filename,target_size=(224,224))\nimg_show = plt.imshow(img)\nplt.show()\nimg = img_to_array(img)\nimg = img.reshape(1,224,224,3)\nimg = img.astype('float32')\nimg = img/255\nkq=np.argmax(model.predict(img),axis=-1)\nif(kq==0):\n    print(\"1000\")\nif(kq==1):\n    print(\"10000\")\nif(kq==2):\n    print(\"100000\")\nif(kq==3):\n    print(\"200\")\nif(kq==4):\n    print(\"2000\")\nif(kq==5):\n    print(\"20000\")\nif(kq==6):\n    print(\"200000\")\nif(kq==7):\n    print(\"500\")\nif(kq==8):\n    print(\"5000\")\nif(kq==9):\n    print(\"50000\")\nif(kq==10):\n    print(\"500000\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:58:29.071445Z","iopub.execute_input":"2022-05-20T08:58:29.071885Z","iopub.status.idle":"2022-05-20T08:58:29.892538Z","shell.execute_reply.started":"2022-05-20T08:58:29.071853Z","shell.execute_reply":"2022-05-20T08:58:29.891551Z"},"trusted":true},"execution_count":32,"outputs":[]}]}