{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model\n# pprevent annoying tensorflow warning\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\nimport warnings\nwarnings.simplefilter(\"ignore\")\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2022-05-20T09:26:12.307186Z","iopub.status.idle":"2022-05-20T09:26:12.307892Z","shell.execute_reply.started":"2022-05-20T09:26:12.307583Z","shell.execute_reply":"2022-05-20T09:26:12.307608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"if you're problem affected badly by huge numbers then it makes sense that MSE will make the model stay away from those big numbers\n\nhttps://www.kaggle.com/discussions/questions-and-answers/160699#896638","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH='../input/vietnamese-foods/Images/Train'\nTEST_PATH='../input/vietnamese-foods/Images/Test'\nIMAGE_SIZE=(224,224)\nBATCH_SIZE=128 #128\nVALIDATE_PATH='../input/vietnamese-foods/Images/Validate'\nclass_count=30","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:43:16.098041Z","iopub.execute_input":"2022-05-20T08:43:16.098781Z","iopub.status.idle":"2022-05-20T08:43:16.102998Z","shell.execute_reply.started":"2022-05-20T08:43:16.098740Z","shell.execute_reply":"2022-05-20T08:43:16.102271Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_generator = ImageDataGenerator(\n    rescale = 1./255,\n    rotation_range = 40, \n    width_shift_range = 0.2, \n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True)\n\nvalidate_generator = ImageDataGenerator(rescale=1./255)\ntest_generator = ImageDataGenerator(rescale=1./255)\n\ntrain_data = train_generator.flow_from_directory(TRAIN_PATH, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\nvalidate_data = validate_generator.flow_from_directory(VALIDATE_PATH, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\ntest_data = test_generator.flow_from_directory(TEST_PATH, target_size=IMAGE_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:43:17.607898Z","iopub.execute_input":"2022-05-20T08:43:17.608441Z","iopub.status.idle":"2022-05-20T08:43:23.664107Z","shell.execute_reply.started":"2022-05-20T08:43:17.608399Z","shell.execute_reply":"2022-05-20T08:43:23.662630Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"classes=list(train_data.class_indices.keys())\nprint(f'classes:{classes} \\r')\nclass_indices=list(train_data.class_indices.values())\nprint(f'class_indices:{class_indices}')\nlabels=test_data.labels\nprint(f'label :{labels}')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:43:28.622869Z","iopub.execute_input":"2022-05-20T08:43:28.623154Z","iopub.status.idle":"2022-05-20T08:43:28.634808Z","shell.execute_reply.started":"2022-05-20T08:43:28.623115Z","shell.execute_reply":"2022-05-20T08:43:28.633891Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2022-05-17T07:37:22.110131Z","iopub.execute_input":"2022-05-17T07:37:22.110507Z","iopub.status.idle":"2022-05-17T07:37:22.115555Z","shell.execute_reply.started":"2022-05-17T07:37:22.110479Z","shell.execute_reply":"2022-05-17T07:37:22.114743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model = VGG19(weights='imagenet', include_top=False)\nlast_output = pretrained_model.output\nx = GlobalAveragePooling2D()(last_output)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.2)(x)\noutputs = Dense(30, activation='softmax')(x)\nmodel1 = Model(inputs=pretrained_model.input, outputs=outputs)\nmodel1.summary() ","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:43:03.603442Z","iopub.execute_input":"2022-05-20T08:43:03.603737Z","iopub.status.idle":"2022-05-20T08:43:08.565479Z","shell.execute_reply.started":"2022-05-20T08:43:03.603702Z","shell.execute_reply":"2022-05-20T08:43:08.564740Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# base_model=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') ","metadata":{"execution":{"iopub.status.busy":"2022-05-17T09:30:47.658371Z","iopub.execute_input":"2022-05-17T09:30:47.658645Z","iopub.status.idle":"2022-05-17T09:30:49.525256Z","shell.execute_reply.started":"2022-05-17T09:30:47.658617Z","shell.execute_reply":"2022-05-17T09:30:49.524249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create an efficientNetB0 model to use for transfer learning\n# img_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)#(224, 224, 3)\n# model_name='EfficientNetB0'\n# base_model=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n# # Note you are always told NOT to make the base model trainable initially- that is WRONG you get better results leaving it trainable\n# # base_model.trainable=True\n# x=base_model.output\n# x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n# x = Dense(1024, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n#                 bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n# x=Dropout(rate=.5, seed=123)(x)\n# x = Dense(512, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n#                 bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n# x=Dropout(rate=.45, seed=123)(x)         \n# output=Dense(class_count, activation='softmax')(x)\n# model=Model(inputs=base_model.input, outputs=output)\nlr=.001 # start with this learning rate\n# model.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy']) ","metadata":{"execution":{"iopub.status.busy":"2022-05-17T09:59:32.625018Z","iopub.execute_input":"2022-05-17T09:59:32.625457Z","iopub.status.idle":"2022-05-17T09:59:34.518496Z","shell.execute_reply.started":"2022-05-17T09:59:32.625394Z","shell.execute_reply":"2022-05-17T09:59:34.517522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model = VGG19(weights='imagenet', include_top=False)\nlast_output = pretrained_model.output\nx = GlobalAveragePooling2D()(last_output)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.4)(x)\noutputs = Dense(30, activation='softmax')(x)\nmodel = Model(inputs=pretrained_model.input, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:43:46.769855Z","iopub.execute_input":"2022-05-20T08:43:46.770132Z","iopub.status.idle":"2022-05-20T08:43:47.204871Z","shell.execute_reply.started":"2022-05-20T08:43:46.770102Z","shell.execute_reply":"2022-05-20T08:43:47.204030Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for layer in pretrained_model.layers: layer.trainable = False #,\n#this data contain ,multiclass so i used 'categorical_crossentropy'\nmodel.compile(optimizer='rmsprop',loss='mse', metrics=['accuracy']) \n#categorical_crossentropy","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:43:49.741388Z","iopub.execute_input":"2022-05-20T08:43:49.741905Z","iopub.status.idle":"2022-05-20T08:43:49.773481Z","shell.execute_reply.started":"2022-05-20T08:43:49.741852Z","shell.execute_reply":"2022-05-20T08:43:49.772646Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# create 2 useful callbacks, one to control the learning rate, and one to control early stopping based on validation loss\nrlronp=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2,verbose=1)\n# estop=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=4, verbose=1,restore_best_weights=True)\n# #rlronp,\n# callbacks=[estop]","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:43:52.438336Z","iopub.execute_input":"2022-05-20T08:43:52.438815Z","iopub.status.idle":"2022-05-20T08:43:52.443792Z","shell.execute_reply.started":"2022-05-20T08:43:52.438776Z","shell.execute_reply":"2022-05-20T08:43:52.442750Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"PATH = 'Models/VGG19'\nBASE_MODEL_BEST = os.path.join(PATH, 'base_model_best.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-05-17T16:34:47.278374Z","iopub.execute_input":"2022-05-17T16:34:47.278648Z","iopub.status.idle":"2022-05-17T16:34:47.283974Z","shell.execute_reply.started":"2022-05-17T16:34:47.278618Z","shell.execute_reply":"2022-05-17T16:34:47.282552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n# base_checkpointer = ModelCheckpoint(\n#     filepath = BASE_MODEL_BEST, \n#     save_best_only = True, \n#     verbose = 1\n# )\n\n# fine_tune_checkpointer = ModelCheckpoint(\n#     filepath = FINE_TUNE_MODEL_BEST, \n#     save_best_only = True,\n#     verbose = 1, )\n\n\n# Stop if no improvement after 3 epochs\n","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:43:55.779380Z","iopub.execute_input":"2022-05-20T08:43:55.779648Z","iopub.status.idle":"2022-05-20T08:43:55.786880Z","shell.execute_reply.started":"2022-05-20T08:43:55.779619Z","shell.execute_reply":"2022-05-20T08:43:55.786011Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**I choosed RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. We could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop.**\n\nhttps://www.kaggle.com/code/yassineghouzam/introduction-to-cnn-keras-0-997-top-6#4.-Evaluate-the-model\n\n**Adaptive Gradient Algorithm (AdaGrad)** \n    \nthat maintains a per-parameter learning rate that improves performance on problems with sparse gradients (e.g. natural language and computer vision problems)          \n.\n**Root Mean Square Propagation (RMSProp)**\n      \nthat also maintains per-parameter learning rates that are adapted based on the average of recent magnitudes of the gradients for the weight (e.g. how quickly it is changing). This means the algorithm does well on online and non-stationary problems (e.g. noisy)\n\nhttps://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/","metadata":{}},{"cell_type":"code","source":"# train the model\nepochs=20\nhistory=model.fit(x=train_data ,epochs=epochs, verbose=1,validation_data=validate_data,\n                  callbacks = [rlronp, early_stopping],shuffle=False, initial_epoch=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T08:44:02.427816Z","iopub.execute_input":"2022-05-20T08:44:02.428416Z","iopub.status.idle":"2022-05-20T09:26:12.303795Z","shell.execute_reply.started":"2022-05-20T08:44:02.428378Z","shell.execute_reply":"2022-05-20T09:26:12.302469Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# vẽ lại quá trình học\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train','Validation'])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import load_img, img_to_array\nimport numpy as np\nimport matplotlib.pyplot as plt\nfilename = \"../input/fruitdataset/train/tomato/Image_11.jpg\"\n\nimg = load_img(filename,target_size=(224,224))\nimg_show = plt.imshow(img)\nplt.show()\nimg = img_to_array(img)\nimg = img.reshape(1,224,224,3)\nimg = img.astype('float32')\nimg = img/255\nkq=np.argmax(model.predict(img),axis=-1)\nif(kq==0):\n    print(\"Banh beo\")\nif(kq==1):\n    print(\"Bot loc\")\nif(kq==2):\n    print(\"Banh Can\")\nif(kq==3):\n    print(\"Banh canh\")\nif(kq==4):\n    print(\"Banh chung\")\nif(kq==5):\n    print(\"Banh cuon\")\nif(kq==6):\n    print(\"Banh duc\")\nif(kq==7):\n    print(\"Banh gio\")\nif(kq==8):\n    print(\"Banh khot\")\nif(kq==9):\n    print(\"Banh mi\")\nif(kq==10):\n    print(\"Banh pia\")\n","metadata":{},"execution_count":null,"outputs":[]}]}